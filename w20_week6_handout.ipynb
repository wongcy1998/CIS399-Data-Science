{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"w20_week6_handout.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"1-ptRpPUCwql","colab_type":"text"},"source":["<h1>\n","<center>\n","Module 6 - from bag to matrix\n","</center>\n","</h1>\n","<div class=h1_cell>\n","<p>\n","This week I want to head in a slightly different direction than the bag of words approach. I want you to consider (and program) a co-occurrence matrix (comat). The comat can lead toward some very cool NLP methods.\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"wBefCDpIGjV0","colab_type":"text"},"source":["#Weird but do it\n","\n","You need to run your notebook with a GPU to get more RAM. Go to Runtime and then Change runtime type. Choose GPU. Now hover over the RAM slider on top right. You should see you have 25GB possible."]},{"cell_type":"markdown","metadata":{"id":"gTBTH67iCwqm","colab_type":"text"},"source":["<h2>\n","<center>\n","Here's the idea\n","</center>\n","</h2>\n","<div class=h1_cell>\n","<p>\n","With bag of words, we threw away context information. If I look up bag_of_words['fawn'], I can see how many times fawn appeared but I don't know anything about what context it appeared in. The context I will be interested in to start with are the two words on either side of fawn, i.e., one word on left and one word on right. If fawn is at beginning or end of sentence, then we will only count one word.\n","<p>\n","To get this new information about context, I will have to go through all the sentences again, and for each word I will update what word is on either side of it. Let me try a small example. Pretend we only have 3 sentences (omitting any wrangling).\n","<p>\n","<pre>\n","I love programming. I love Math. I tolerate Biology.\n","</pre>\n","<p>\n","Check out the comat I would build from these sentences.\n","<p>\n","<img src='https://cdn-images-1.medium.com/max/1600/1*1p0geczj9KbJvwYi25B2Jg.png'>\n","<p>\n","You should notice that the row names and column names are symmetric. They are made up of the unique words in all the sentences. You should also note that sentences matter. For instance, if you remove the periods, then you would get `Math` coming right before `I`. So should be an entry for `[Math, I]` of `1`. But it is zero. We do not cross sentence boundaries to check for co-occurrences.\n","<p>\n","Also note that we are looking at either side of a word for co-occurrences. Hence, `I` shows up with `love` twice and `love` shows up with `I` twice.\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"x7q4pGRlCwqn","colab_type":"text"},"source":["<h2>\n","There is one parameter\n","</h2>\n","\n","\n","The parameter for a comat is how far from the target word we check. In the example above, the parameter value is 1 - check 1 word on either side. But I could set it to a larger integer. If I make it big enough, I'll likely get most of the sentence as the context.\n","<p>\n","Reminder: parameters like this in data science are often called hyper-parameters. The \"K\" in KNN is a hyper-parameter.\n","\n","To start, you can assume the window is a constant 1. Later, I'll ask you to add a parameter that allows you to choose the window size, i.e.,  look 2 words out or 3 words out, etc. The larger the parameter, the more context you are picking up.\n","\n","But to keep it simple, we assume window size 1 for now."]},{"cell_type":"markdown","metadata":{"id":"mXD30R0V5abo","colab_type":"text"},"source":["## Bring in your library functions"]},{"cell_type":"code","metadata":{"id":"j_GdU8ACeitW","colab_type":"code","outputId":"70743337-135e-4d67-cf5d-5b0da9e696a5","executionInfo":{"status":"ok","timestamp":1581543394576,"user_tz":480,"elapsed":1881,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["#flush the old directory\n","!rm -r  'w20_ds_library'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'w20_ds_library': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rPISZH5nclhU","colab_type":"code","colab":{}},"source":["my_github_name = 'FutureDeus'  #replace with your account name"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NuaxZXKXcrNL","colab_type":"code","colab":{}},"source":["clone_url = f'https://github.com/{my_github_name}/w20_ds_library.git'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Rmp86ySdkr4z","outputId":"9f859f4a-ba17-4740-da20-d93398376e1f","executionInfo":{"status":"ok","timestamp":1581543403084,"user_tz":480,"elapsed":10377,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["#get the latest.\n","!git clone $clone_url \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'w20_ds_library'...\n","remote: Enumerating objects: 87, done.\u001b[K\n","remote: Counting objects: 100% (87/87), done.\u001b[K\n","remote: Compressing objects: 100% (86/86), done.\u001b[K\n","remote: Total 87 (delta 54), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (87/87), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9r8-rTeMkr5C","outputId":"87700f37-08fc-43ac-fde6-41ceb85447dd","executionInfo":{"status":"ok","timestamp":1581543404126,"user_tz":480,"elapsed":11411,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from w20_ds_library import *"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RNBHsCaJq1sd","colab_type":"text"},"source":["<h2>Challenge 1: A warm-up problem</h2>\n","\n","Jargon alert. I will use *co-occurence matrix*, *comat* and *matrix* interchangeably in this module.\n","\n","I am going to eventually ask you to build your own co-occurence matrix  using the sentences from the gothic authors. This means you need an algorithm for sliding a window along a sentence. But before getting to that on the big table, it helped me debug my code by first looking at a small problem to make sure I got that right. I'll lead you through a warm-up exercise to help you debug your algorithm for moving your window as you move across a sentence.\n","\n","  I am not going to worry about processing speed but instead use a dataframe to hold my matrix (probably the slowest option) because it is easier to visualize. When we move to big table, you will need a Python data structure to speed things up.\n","\n","Let's use the 3 sentences at the top of the notebook for our warm-up."]},{"cell_type":"code","metadata":{"id":"Hisw6EGUWAzj","colab_type":"code","colab":{}},"source":["sentences_3 = ['I love programming.', 'I love Math.', 'I tolerate Biology.']  #Note that at top none of these wrangled. Even period left in as word."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wC6koBEtXBhh","colab_type":"code","outputId":"e0173681-936d-4e85-d5cc-a426f1d3e939","executionInfo":{"status":"ok","timestamp":1581543404127,"user_tz":480,"elapsed":11403,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["wrangled_3 = [get_clean_words(swords,s) for s in sentences_3]  #I am going to wrangle them.\n","wrangled_3"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['love', 'programming'], ['love', 'math'], ['tolerate', 'biology']]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"nlbAoLn4EFul","colab_type":"text"},"source":["Write a function that will find the unique words (as a list) from the list of sentence words. In essence, flatten the list above and remove duplicates.\n"]},{"cell_type":"code","metadata":{"id":"GFf1T3hhCwrZ","colab_type":"code","colab":{}},"source":["def unique_words(sentences:list) -> list:\n","  assert isinstance(sentences, list), f'sentences must be a list but saw a {type(sentences)}'\n","  assert all([isinstance(inner, list) for inner in sentences]), f'expecting sentences to be a list of lists'\n","\n","  #your code here\n","  return list({j for i in sentences for j in i})\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3oAq8Q3DYBCq","colab_type":"code","outputId":"34ed8a18-1127-4de5-9caa-a51323529856","executionInfo":{"status":"ok","timestamp":1581543404129,"user_tz":480,"elapsed":11391,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["unique_3 = sorted(unique_words(wrangled_3)) # ['biology', 'love', 'math', 'programming', 'tolerate']\n","unique_3"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['biology', 'love', 'math', 'programming', 'tolerate']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"9C1RXzD9EYE7","colab_type":"text"},"source":["Building the table is pretty easy."]},{"cell_type":"code","metadata":{"id":"PLCS3vXPZMfU","colab_type":"code","colab":{}},"source":["df_3 = pd.DataFrame(data=0, index=unique_3, columns=unique_3, dtype=int, copy=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iftWwwQIZduS","colab_type":"code","outputId":"1d0a1b10-4094-495a-c83f-c399fd2fc6e8","executionInfo":{"status":"ok","timestamp":1581543404129,"user_tz":480,"elapsed":11380,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["df_3.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>biology</th>\n","      <th>love</th>\n","      <th>math</th>\n","      <th>programming</th>\n","      <th>tolerate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>biology</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>love</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>math</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>programming</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>tolerate</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             biology  love  math  programming  tolerate\n","biology            0     0     0            0         0\n","love               0     0     0            0         0\n","math               0     0     0            0         0\n","programming        0     0     0            0         0\n","tolerate           0     0     0            0         0"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"DApUYClFZlKR","colab_type":"text"},"source":["Ok, go to it. Write the code that will fill in the table using window size 1 for sentences in wrangled_3.\n","<pre>\n","\n","                                  biology  love\tmath\tprogramming\ttolerate\n","biology\t                         0\t   0\t      0\t   0\t          1\n","love\t                            0\t   0\t      1\t   1              0\n","math\t                            0\t   1      \t0\t   0\t          0\n","programming\t                     0\t   1\t      0\t   0\t          0\n","tolerate\t                        1\t   0\t      0\t   0\t          0\n","</pre>"]},{"cell_type":"code","metadata":{"id":"IQXRam8gZurh","colab_type":"code","colab":{}},"source":["#your code here\n","\n","for i in wrangled_3:\n","  i_length = len(i)\n","  if i_length <= 1:\n","    continue\n","  else:\n","    for j in range(i_length):\n","      if (j + 1) < i_length:\n","        df_3.loc[i[j], i[j+1]] += 1\n","      if (j - 1) >= 0:\n","        df_3.loc[i[j], i[j-1]] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8KlS8aVlEicl","colab_type":"code","outputId":"50a06f55-f760-481d-da21-8d512daf90c8","executionInfo":{"status":"ok","timestamp":1581543404130,"user_tz":480,"elapsed":11372,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["df_3.head()  #check against my answer above"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>biology</th>\n","      <th>love</th>\n","      <th>math</th>\n","      <th>programming</th>\n","      <th>tolerate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>biology</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>love</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>math</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>programming</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>tolerate</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             biology  love  math  programming  tolerate\n","biology            0     0     0            0         1\n","love               0     0     1            1         0\n","math               0     1     0            0         0\n","programming        0     1     0            0         0\n","tolerate           1     0     0            0         0"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"mBPnpePLCwqq","colab_type":"text"},"source":["<h2>\n","Challenge 2\n","</h2>\n","\n","First let's bring the gothic table in.\n"]},{"cell_type":"code","metadata":{"id":"573YHkiKCwqr","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","gothic_table = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQqRwyE0ceZREKqhuaOw8uQguTG6Alr5kocggvAnczrWaimXE8ncR--GC0o_PyVDlb-R6Z60v-XaWm9/pub?output=csv',\n","                          encoding='utf-8')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HO4nRV4ECwqu","colab_type":"code","outputId":"eadc6fce-6bec-44d5-ac72-c7d2a2d2f5ad","executionInfo":{"status":"ok","timestamp":1581543407559,"user_tz":480,"elapsed":14789,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["gothic_table.head()\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>author</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id26305</td>\n","      <td>This process, however, afforded me no means of...</td>\n","      <td>EAP</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id17569</td>\n","      <td>It never once occurred to me that the fumbling...</td>\n","      <td>HPL</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id11008</td>\n","      <td>In his left hand was a gold snuff box, from wh...</td>\n","      <td>EAP</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id27763</td>\n","      <td>How lovely is spring As we looked from Windsor...</td>\n","      <td>MWS</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id12958</td>\n","      <td>Finding nothing else, not even gold, the Super...</td>\n","      <td>HPL</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                               text author\n","0  id26305  This process, however, afforded me no means of...    EAP\n","1  id17569  It never once occurred to me that the fumbling...    HPL\n","2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n","3  id27763  How lovely is spring As we looked from Windsor...    MWS\n","4  id12958  Finding nothing else, not even gold, the Super...    HPL"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"ZV8OXkTMCwqz","colab_type":"code","outputId":"ffd4dd44-01c4-41d6-fa3d-0cbf7df14030","executionInfo":{"status":"ok","timestamp":1581543407559,"user_tz":480,"elapsed":14782,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["len(gothic_table)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19579"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"U0B9Jipp5jjt","colab_type":"text"},"source":["##Not doing prediction\n","\n","We are going to return to looking at vectors and cosine similarity. So we don't need the author column - we are not doing prediction. Only care about the text column."]},{"cell_type":"markdown","metadata":{"id":"Ry4yL9iXCwrY","colab_type":"text"},"source":["<h2>\n","Move data out of gothic_table\n","</h2>\n","\n","We have to start getting serious about processing time this week. We will be building some big data structures. The first thing to note is that `gothic_table.iterrows()` is about as slow as you can get. To avoid using it more than once, let's pull the text from the rows, wrangle it, then store the wrangled sentence in a list. So we will have a list of lists.\n","\n","I think this will pay off for us later. We now can get rid of `gothic_table` and iterate over a pyhon list (fast!). Go ahead and build `sentences`.\n","\n","\n","##Important Point!\n","\n","I want all the clean words in a sentence including duplicates. Last week we removed duplicates. Don't do that here. Here are first 2 entries that I get:\n","<pre>\n","[['process',\n","  'however',\n","  'afforded',\n","  'means',\n","  'ascertaining',\n","  'dimensions',\n","  'dungeon',\n","  'might',\n","  'make',\n","  'circuit',\n","  'return',\n","  'point',\n","  'whence',\n","  'set',\n","  'without',\n","  'aware',\n","  'fact',\n","  'perfectly',\n","  'uniform',\n","  'seemed',\n","  'wall'],\n"," ['never', 'occurred', 'fumbling', 'might', 'mere', 'mistake']]\n"," </pre>"]},{"cell_type":"code","metadata":{"id":"rSfb-l8-itZA","colab_type":"code","outputId":"d4234cb6-d36c-42d5-ec79-0fc496afe05e","executionInfo":{"status":"ok","timestamp":1581543425615,"user_tz":480,"elapsed":32831,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["%%time\n","\n","#your code here (17s for me)\n","\n","sentences = [get_clean_words(swords,row['text']) for index, row in gothic_table.iterrows()]\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 18 s, sys: 45.9 ms, total: 18 s\n","Wall time: 18 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tybQyuDaC7lN","colab_type":"code","outputId":"ccb5197a-90c1-42fd-c0ef-0eb853cfd474","executionInfo":{"status":"ok","timestamp":1581543425616,"user_tz":480,"elapsed":32826,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["sentences[:2]  #check against above"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['process',\n","  'however',\n","  'afforded',\n","  'means',\n","  'ascertaining',\n","  'dimensions',\n","  'dungeon',\n","  'might',\n","  'make',\n","  'circuit',\n","  'return',\n","  'point',\n","  'whence',\n","  'set',\n","  'without',\n","  'aware',\n","  'fact',\n","  'perfectly',\n","  'uniform',\n","  'seemed',\n","  'wall'],\n"," ['never', 'occurred', 'fumbling', 'might', 'mere', 'mistake']]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"IIbXaJuIpt8B","colab_type":"text"},"source":["## Let's get the unique words\n","\n","We can use these as our row and column labels."]},{"cell_type":"code","metadata":{"id":"XFyCExuOCwrc","colab_type":"code","outputId":"66838c1d-e39a-490b-a0b6-58197b9023bc","executionInfo":{"status":"ok","timestamp":1581543425616,"user_tz":480,"elapsed":32819,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["%time vocab = unique_words(sentences)  #Wall time: 65.7 ms"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 40 ms, sys: 968 Âµs, total: 41 ms\n","Wall time: 40.1 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HP_b4p8OCwrg","colab_type":"code","outputId":"5e2c1f41-e70b-4b1b-9bbe-e0e2161690d9","executionInfo":{"status":"ok","timestamp":1581543425617,"user_tz":480,"elapsed":32813,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["'''\n","['aaem',\n"," 'ab',\n"," 'aback',\n"," 'abaft',\n"," 'abandon',\n"," 'abandoned',\n"," 'abandoning',\n"," 'abandonment',\n"," 'abaout',\n"," 'abased']\n"," '''\n","\n","sorted_vocab = sorted(vocab)\n","sorted_vocab[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['aaem',\n"," 'ab',\n"," 'aback',\n"," 'abaft',\n"," 'abandon',\n"," 'abandoned',\n"," 'abandoning',\n"," 'abandonment',\n"," 'abaout',\n"," 'abased']"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"dGGrOdJFCwrk","colab_type":"code","outputId":"606ca084-31a8-4caa-b4c3-f38a904596ab","executionInfo":{"status":"ok","timestamp":1581543425617,"user_tz":480,"elapsed":32807,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["len(sorted_vocab)  #24944 - so our comat will be 24944x24944"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["24944"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"pILywyuNCwqo","colab_type":"text"},"source":["<h2>\n","Challenge 3: you in charge\n","</h2>\n","\n","Normally I would guide you through main steps and have you fill in pieces. I am going to cut you loose for this assignment. You can solve the problem in any way you want as long as you match my results.\n","\n","I hope you have inferred from the sample comat above that your comat will be N by N where `N = len(sorted_vocab)`. Roughly 25K by 25K. Yikes. Every unique word is a row/column label.\n"]},{"cell_type":"markdown","metadata":{"id":"AUrRWHGSEkuN","colab_type":"text"},"source":["## Ok, but what exactly should you do\n","\n","You need a Python representation of the dataframe df_3 we created above. But now instead of a 5x5, you need a 24944x24944. This is your comat table.\n","\n","You will then need to fill in values in your comat. As you go through sentences, you will check the words on either side of a word and update counts accordingly. For this challenge, you only need to look one word on either side, i.e., use a window size of 1."]},{"cell_type":"markdown","metadata":{"id":"d8822ZHSpZb5","colab_type":"text"},"source":["##I am ok with you experimenting\n","\n","I want you to write your own versions of KNN, Naive Bayes, etc. I think it gives you a deeper understanding of the models. And we can more easily make changes to them. But when it comes to a comat, I am ok if you want to try to reduce its memory footprint. And by doing so, you will likely improve speed.\n","\n","That said, I used raw Python data structures and that is what you see for my times."]},{"cell_type":"markdown","metadata":{"id":"UM8gU729IO0g","colab_type":"text"},"source":["## Your target\n","\n","I have a problem showing you a 25Kx25K matrix. Too much to print! So I instead will try this. I converted the data structure I was using to a list of tuples, sorted on the word. Each tuple/pair has the word and a sum of the columns for that word in my comat. So if you look at the row 'abandoned', and sum its 24944 columns, you get 53.\n","<pre>\n","[('aaem', 1),\n"," ('ab', 2),\n"," ('aback', 4),\n"," ('abaft', 2),\n"," ('abandon', 20),\n"," ('abandoned', 53),\n"," ('abandoning', 6),\n"," ('abandonment', 9),\n"," ('abaout', 46),\n"," ('abased', 1),\n"," ('abasement', 2),\n"," ('abashed', 2),\n"," ('abashment', 2),\n"," ('abate', 3),\n"," ('abated', 2),\n"," ('abatement', 4),\n"," ('abating', 1),\n"," ('abbey', 7),\n"," ('abbeys', 1),\n"," ('abbreviation', 3)]\n"," </pre>\n","Make sure you match."]},{"cell_type":"code","metadata":{"id":"MCS9xmVXmDy_","colab_type":"code","colab":{}},"source":["#your code here for building your matrix\n","matrix = pd.DataFrame(data=0, index=sorted_vocab, columns=sorted_vocab, dtype=int, copy=False)\n","for i in sentences:\n","  i_length = len(i) - 1\n","  for j in range(i_length + 1):\n","    if (j - 1) >= 0:\n","      for k in range(1):\n","        matrix.loc[i[j], i[j-(k+1)]] += 1\n","    elif j != 0:\n","      for k in range(j):\n","        matrix.loc[i[j], i[j-(k+1)]] += 1\n","    if (j + 1) <= i_length:\n","      for k in range(1):\n","        matrix.loc[i[j], i[j+(k+1)]] += 1\n","    elif j != i_length:\n","      for k in range(i_length-(j)):\n","        matrix.loc[i[j], i[j+(k+1)]] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KaDESgwEmIOS","colab_type":"code","outputId":"20880696-3dc7-4187-aaba-01e8600c4948","executionInfo":{"status":"ok","timestamp":1581543627043,"user_tz":480,"elapsed":234225,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":56}},"source":["#your code here for generating list of word-sum pairs to see if you match mine above\n","matrix_list = [(i, matrix[i].sum()) for i in sorted_vocab]\n","print(matrix_list[:20])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('aaem', 1), ('ab', 2), ('aback', 4), ('abaft', 2), ('abandon', 20), ('abandoned', 53), ('abandoning', 6), ('abandonment', 9), ('abaout', 46), ('abased', 1), ('abasement', 2), ('abashed', 2), ('abashment', 2), ('abate', 3), ('abated', 2), ('abatement', 4), ('abating', 1), ('abbey', 7), ('abbeys', 1), ('abbreviation', 3)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vr8czh-s52A4","colab_type":"text"},"source":["<h2>Some tests for you to run</h2>\n","\n","First, define a function `get_matrix_row` that will pull out a row given a comat (i.e., matrix) and a row word. I'm not showing you my function because it is particular to my implementation of comat. You should define a version that makes sense for your comat.\n","\n","## Object instead?\n","\n","I was tempted to define a class comat here and then add get_matrix_row as a method. In essence, hide my implementation behind a set of getters and setters. I decided not to, but I could have gone either way."]},{"cell_type":"code","metadata":{"id":"ws-HYZxk8bHr","colab_type":"code","colab":{}},"source":["def get_matrix_row(comat, word:str) -> list:\n","  assert isinstance(word, str), f'word must be a str but saw a {type(word)}'\n","  \n","  #your code here\n","  return comat.loc[word].tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6wS69j9Cwtv","colab_type":"code","outputId":"2cbda91a-5cbe-4e30-cd41-2cc6747624ff","executionInfo":{"status":"ok","timestamp":1581543627044,"user_tz":480,"elapsed":234214,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["monster_row = get_matrix_row(matrix, 'monster')\n","monster_row.count(0)  #24875  - pretty sparse"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["24875"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"qKbvCV0qhuE8","colab_type":"text"},"source":["## One other thing\n","\n","Make sure your cosine_similarity function handles a vector of 0s. This situation will crop up this week. In particular, I found these words have all zeroes:\n","<pre>\n","bawling\n","enmeshed\n","funnin\n","miscalculated\n","mountebanks\n","pleases\n","rouge\n","</pre>"]},{"cell_type":"code","metadata":{"id":"83EbZabgCPmO","colab_type":"code","outputId":"d3ece62f-c7b7-4592-cd1a-e6309e892202","executionInfo":{"status":"ok","timestamp":1581543627045,"user_tz":480,"elapsed":234208,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["cosine_similarity([0,0,0],[1,1,1])  #0.0"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"SUvus1VoAo3o","colab_type":"code","outputId":"38e265ac-09bd-4689-da05-0b2b7e861502","executionInfo":{"status":"ok","timestamp":1581543627045,"user_tz":480,"elapsed":234201,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["cosine_similarity(monster_row, monster_row)  #just checking - should be 1"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"ZLguLTDifiJ6","colab_type":"text"},"source":["Let's check out some words for similarity."]},{"cell_type":"code","metadata":{"id":"gAvOGyutCwup","colab_type":"code","outputId":"33c5481a-a616-4f44-adf7-b80036053436","executionInfo":{"status":"ok","timestamp":1581543627045,"user_tz":480,"elapsed":234192,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["frankenstein_row = get_matrix_row(matrix, 'frankenstein')\n","cosine_similarity(monster_row, frankenstein_row)  #0.07273929674533079"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.07273929674533079"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"jvf9WLY0Cwus","colab_type":"code","outputId":"b027036e-95c1-4c82-be36-8531ac7ce699","executionInfo":{"status":"ok","timestamp":1581543627046,"user_tz":480,"elapsed":234184,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["cosine_similarity(get_matrix_row(matrix, 'laboratory'), monster_row)  #0.0"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"4QM6H9824var","colab_type":"text"},"source":["Some more tests."]},{"cell_type":"code","metadata":{"id":"PyF2CiD87W_P","colab_type":"code","outputId":"53909e4b-f6fd-486b-afbb-0023ffd66fd3","executionInfo":{"status":"ok","timestamp":1581543627046,"user_tz":480,"elapsed":234175,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["red_row = get_matrix_row(matrix, 'red')\n","blue_row = get_matrix_row(matrix, 'blue')\n","cosine_similarity(red_row, blue_row)  #0.19115696577049454"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.19115696577049454"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"3kXP2oqe7fTP","colab_type":"code","outputId":"e196fb33-f2dd-4954-ec39-0d2ffc89dd3e","executionInfo":{"status":"ok","timestamp":1581543627046,"user_tz":480,"elapsed":234163,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["green_row = get_matrix_row(matrix, 'green')\n","\n","cosine_similarity(red_row, green_row)  #0.05128239532643232"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.05128239532643232"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"KvyQAAHf-BOp","colab_type":"code","outputId":"c68cec6e-5122-4a4d-9704-335cfaa8c4bf","executionInfo":{"status":"ok","timestamp":1581543627047,"user_tz":480,"elapsed":234155,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["mad_row = get_matrix_row(matrix, 'mad')\n","sad_row = get_matrix_row(matrix, 'sad')\n","cosine_similarity(mad_row, sad_row)  #0.027606198265256506"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.027606198265256506"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"ifgcPMcSCwu1","colab_type":"text"},"source":["<h2>\n","Challenge 5\n","</h2>\n","\n","Instead of just blindly searching for words that are similar, let's use one of our ideas from a previous model. As part of doing KNN, we computed the k closest rows. We then voted but we are going to skip that part. I only want the first part: produce a list of sorted distances.\n","<p>\n","BTW: this is where things slowed down and I was getting 4 minutes on colab.\n","</div>"]},{"cell_type":"code","metadata":{"id":"5SyChu_tCwu1","colab_type":"code","colab":{}},"source":["def word_distances(matrix, word:str) -> list:\n","    assert isinstance(word, str), f'word must be a str but saw a {type(word)}'\n","    \n","    #your code here\n","    word_vect = get_matrix_row(matrix, word)\n","    return sorted([(index, cosine_similarity(word_vect, row.tolist())) for index, row in matrix.drop(word).iterrows()], key=lambda x: x[1], reverse = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O7YBJuuQHWai","colab_type":"text"},"source":["Here is a fast test to see if you are on track."]},{"cell_type":"code","metadata":{"id":"fnyTt7xSHwfS","colab_type":"code","outputId":"af6ef83c-404b-405e-f2e3-42baedb0a436","executionInfo":{"status":"ok","timestamp":1581543627047,"user_tz":480,"elapsed":234145,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["test_word = sorted_vocab[0]  #get the first word as test\n","test_word"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'aaem'"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"Ke9SKxDhJnjZ","colab_type":"text"},"source":["You will need to figure out how to slice off the first 1000 rows of your matrix. It will depend on how you are representing the matrix."]},{"cell_type":"code","metadata":{"id":"9yDVWhEvIZjJ","colab_type":"code","colab":{}},"source":["slice_1000 = matrix[:1000]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvmUyanvHcce","colab_type":"code","outputId":"81c505ac-b20d-44d1-fc30-9c240ea0950e","executionInfo":{"status":"ok","timestamp":1581543642255,"user_tz":480,"elapsed":249335,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["%time aaem_distances = word_distances(slice_1000, 'aaem') #only use first 1000 rows - Wall time: 10 s"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 14.9 s, sys: 92 ms, total: 15 s\n","Wall time: 15 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z8pnhVUoJCvu","colab_type":"code","outputId":"f27186c2-38cc-41e0-ef63-9bca42413cad","executionInfo":{"status":"ok","timestamp":1581543642255,"user_tz":480,"elapsed":249333,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["aaem_distances[:10]  #just for debugging"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('alludes', 0.4472135954999579),\n"," ('account', 0.05670479771237427),\n"," ('air', 0.038180177416060626),\n"," ('among', 0.029235267310234306),\n"," ('ab', 0.0),\n"," ('aback', 0.0),\n"," ('abaft', 0.0),\n"," ('abandon', 0.0),\n"," ('abandoned', 0.0),\n"," ('abandoning', 0.0)]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"mKQ0LhSiKAH3","colab_type":"text"},"source":["<pre>\n","[('alludes', 0.4472135954999579),\n"," ('account', 0.05670479771237427),\n"," ('air', 0.038180177416060626),\n"," ('among', 0.029235267310234306),\n"," ('ab', 0.0),\n"," ('aback', 0.0),\n"," ('abaft', 0.0),\n"," ('abandon', 0.0),\n"," ('abandoned', 0.0),\n"," ('abandoning', 0.0)]\n"," </pre>\n","\n","If you are matching my results, go for the big enchilada. Find the closest words to `monster` in the full matrix."]},{"cell_type":"code","metadata":{"id":"-JO7W8kwCwu7","colab_type":"code","outputId":"fb8cb390-4d12-43bd-ea6e-a09caa8e0a27","executionInfo":{"status":"ok","timestamp":1581544016832,"user_tz":480,"elapsed":623908,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["%time monster_distances = word_distances(matrix, 'monster') #on colab Wall time: 4min 51s"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 6min 12s, sys: 2.22 s, total: 6min 14s\n","Wall time: 6min 14s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h2Rk5ob1Cwu-","colab_type":"code","outputId":"69504a57-6c23-4093-e634-e7a4285dd535","executionInfo":{"status":"ok","timestamp":1581544016833,"user_tz":480,"elapsed":623907,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["'''\n","[('uncomplainingly', 0.23145502494313785),\n"," ('decipherer', 0.2182178902359924),\n"," ('hernani', 0.2182178902359924),\n"," ('mimes', 0.2182178902359924),\n"," ('skulking', 0.2182178902359924),\n"," ('ever', 0.19551857514700038),\n"," ('thought', 0.190143522496192),\n"," ('sentience', 0.17251638983558856),\n"," ('never', 0.1697162329953409),\n"," ('indistinctly', 0.1690308509457033)]\n","'''\n","monster_distances[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('uncomplainingly', 0.23145502494313785),\n"," ('decipherer', 0.2182178902359924),\n"," ('hernani', 0.2182178902359924),\n"," ('mimes', 0.2182178902359924),\n"," ('skulking', 0.2182178902359924),\n"," ('ever', 0.19551857514700038),\n"," ('thought', 0.190143522496192),\n"," ('sentience', 0.17251638983558856),\n"," ('never', 0.1697162329953409),\n"," ('indistinctly', 0.1690308509457033)]"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"LiOEnQrgCwvA","colab_type":"code","outputId":"7e7737ea-e86f-4d3c-9a8a-abe66af3d9e6","executionInfo":{"status":"ok","timestamp":1581544388348,"user_tz":480,"elapsed":995419,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["%time red_distances = word_distances(matrix, 'red')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 6min 11s, sys: 44.8 ms, total: 6min 11s\n","Wall time: 6min 11s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ODzv7m9TCwvZ","colab_type":"code","outputId":"cfb26460-b9b5-4ce3-d67a-0310a9bda7a0","executionInfo":{"status":"ok","timestamp":1581544388348,"user_tz":480,"elapsed":995417,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["'''\n","[('cancelled', 0.36380343755449945),\n"," ('engulfs', 0.36380343755449945),\n"," ('ignominy', 0.36380343755449945),\n"," ('satiated', 0.3451342449813167),\n"," ('hearkening', 0.30012252399939043),\n"," ('snub', 0.30012252399939043),\n"," ('certificates', 0.2970442628930023),\n"," ('unto', 0.2684377460965796),\n"," ('downcast', 0.25928148942086576),\n"," ('accrued', 0.25724787771376323)]\n","'''\n","red_distances[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('cancelled', 0.36380343755449945),\n"," ('engulfs', 0.36380343755449945),\n"," ('ignominy', 0.36380343755449945),\n"," ('satiated', 0.3451342449813167),\n"," ('hearkening', 0.30012252399939043),\n"," ('snub', 0.30012252399939043),\n"," ('certificates', 0.2970442628930023),\n"," ('unto', 0.2684377460965796),\n"," ('downcast', 0.25928148942086576),\n"," ('accrued', 0.25724787771376323)]"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"EZoZ903gCwvv","colab_type":"code","outputId":"1db94c6b-1aa2-4505-9c80-8a32317c1cf8","executionInfo":{"status":"ok","timestamp":1581544757188,"user_tz":480,"elapsed":1364255,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["%time happy_distances = word_distances(matrix, 'happy')  #Wall time: 4min 55s"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 6min 8s, sys: 55.7 ms, total: 6min 8s\n","Wall time: 6min 8s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2_3iRhzCwvy","colab_type":"code","outputId":"e9e7c572-68a5-4f94-a343-cf9fd61806a9","executionInfo":{"status":"ok","timestamp":1581544757189,"user_tz":480,"elapsed":1364255,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["'''\n","[('would', 0.3152106507470724),\n"," ('shall', 0.30266871241659793),\n"," ('could', 0.2919346540577332),\n"," ('might', 0.27465783756205087),\n"," ('saw', 0.2740787935057763),\n"," ('heard', 0.27217080979442226),\n"," ('seen', 0.2693112605933227),\n"," ('opportunity', 0.2657880650250036),\n"," ('forget', 0.25513799879424426),\n"," ('yet', 0.25421102244707794)]\n","'''\n","\n","happy_distances[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('would', 0.3152106507470724),\n"," ('shall', 0.30266871241659793),\n"," ('could', 0.2919346540577332),\n"," ('might', 0.27465783756205087),\n"," ('saw', 0.2740787935057763),\n"," ('heard', 0.27217080979442226),\n"," ('seen', 0.2693112605933227),\n"," ('opportunity', 0.2657880650250036),\n"," ('forget', 0.25513799879424426),\n"," ('yet', 0.25421102244707794)]"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"mMoj2R4M-SbU","colab_type":"text"},"source":["#Challenge 6\n","\n","Finally, I am going to ask you to generalize your code to allow creating different comats based on windown size. Our current matrix was created using window size of 1. I'd like to create a comat with an arbitrary size window that is specificed in a parameter `window_size`. Please fill in the function below so that you can call it with different window sizes and create the corresponding comat.\n","\n","Again, I'll give you a target that has words and their row sums so you can see if you are matching my results."]},{"cell_type":"code","metadata":{"id":"9YXO40ZJAar1","colab_type":"code","colab":{}},"source":["def build_matrix(vocab:list, sentences:list, window_size):\n","  assert isinstance(vocab, list), f'vocab must be a list but saw a {type(vocab)}'\n","  assert all([isinstance(inner, str) for inner in vocab]), f'expecting vocab to be a list of strings'\n","  assert isinstance(sentences, list), f'sentences must be a list but saw a {type(sentences)}'\n","  assert all([isinstance(inner, list) for inner in sentences]), f'expecting sentences to be a list of lists'\n","  assert isinstance(window_size, int), f'window_size must be an int but saw a {type(window_size)}'\n","\n","  #your code here\n","  matrix = pd.DataFrame(data=0, index=vocab, columns=vocab, dtype=int, copy=False)\n","  for i in sentences:\n","    i_length = len(i) - 1\n","    for j in range(i_length + 1):\n","      if (j - window_size) >= 0:\n","        for k in range(window_size):\n","          matrix.loc[i[j], i[j-(k+1)]] += 1\n","      elif j != 0:\n","        for k in range(j):\n","          matrix.loc[i[j], i[j-(k+1)]] += 1\n","      if (j + window_size) <= i_length:\n","        for k in range(window_size):\n","          matrix.loc[i[j], i[j+(k+1)]] += 1\n","      elif j != i_length:\n","        for k in range(i_length-(j)):\n","          matrix.loc[i[j], i[j+(k+1)]] += 1\n","  return matrix\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hv9bAO_KXrJ1","colab_type":"text"},"source":["##Test\n","\n","We built matrix by hand earlier. Check if your new function produces the same thing when using windown size 1. BTW: this is where you need the extra RAM!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sXaq5dePAKjD","colab":{}},"source":["matrix1 = build_matrix(sorted_vocab, sentences, 1)  #about 3 minutes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bs8HzlifG5bb","colab_type":"code","outputId":"7a3138c8-db65-4ea0-87ba-89b2546cab02","executionInfo":{"status":"ok","timestamp":1581546308319,"user_tz":480,"elapsed":2406,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["matrix.equals(matrix1) #True - same as one we built earlier"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"VgF9z8f-X_DQ","colab_type":"text"},"source":["##Test with window size 4"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VRhQoshpAKjG","colab":{}},"source":["matrix4 = build_matrix(sorted_vocab, sentences, 4)  #try window size 4"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bGOf_N_TFwFg","colab_type":"text"},"source":["Go ahead and generate word-sum pairs from matrix4 and check your answer against mine below.\n","<pre>\n","target[:20]\n","\n","[('aaem', 4),\n"," ('ab', 6),\n"," ('aback', 11),\n"," ('abaft', 5),\n"," ('abandon', 66),\n"," ('abandoned', 186),\n"," ('abandoning', 21),\n"," ('abandonment', 35),\n"," ('abaout', 162),\n"," ('abased', 4),\n"," ('abasement', 8),\n"," ('abashed', 5),\n"," ('abashment', 7),\n"," ('abate', 12),\n"," ('abated', 8),\n"," ('abatement', 14),\n"," ('abating', 4),\n"," ('abbey', 25),\n"," ('abbeys', 4),\n"," ('abbreviation', 12)]\n"," </pre>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9CFmYS23AKjT","colab":{}},"source":["target = [(i, matrix4[i].sum()) for i in sorted_vocab]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i-TH6HxqAKjt","outputId":"e1afece1-7c11-45ac-aac7-cf4a26045fee","executionInfo":{"status":"ok","timestamp":1581545630256,"user_tz":480,"elapsed":2237307,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["target[:20]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('aaem', 4),\n"," ('ab', 6),\n"," ('aback', 11),\n"," ('abaft', 5),\n"," ('abandon', 66),\n"," ('abandoned', 186),\n"," ('abandoning', 21),\n"," ('abandonment', 35),\n"," ('abaout', 162),\n"," ('abased', 4),\n"," ('abasement', 8),\n"," ('abashed', 5),\n"," ('abashment', 7),\n"," ('abate', 12),\n"," ('abated', 8),\n"," ('abatement', 14),\n"," ('abating', 4),\n"," ('abbey', 25),\n"," ('abbeys', 4),\n"," ('abbreviation', 12)]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"yjgRThg7_1Yq","colab_type":"text"},"source":["Let's check distances we got with window size 1 against window size 4. My prediction is that they will be stronger now that we are taking more context."]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"2dfde545-7c7e-48b9-97ef-9da8ac31538c","id":"argZu7zj_8u1","executionInfo":{"status":"ok","timestamp":1581545630256,"user_tz":480,"elapsed":2237299,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["\n","cosine_similarity(get_matrix_row(matrix4, 'frankenstein'), get_matrix_row(matrix4, 'monster'))  #was 0.07273929674533079 - now 0.07604031408080632"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.07604031408080632"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"DXmFhhyyD9lY","colab_type":"code","outputId":"70d8c681-846a-46b3-9474-acb70e715a77","executionInfo":{"status":"ok","timestamp":1581545630257,"user_tz":480,"elapsed":2237293,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["cosine_similarity(get_matrix_row(matrix4, 'red'), get_matrix_row(matrix4, 'blue'))  #was #0.19115696577049454 - now 0.24893166777030223"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.24893166777030223"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"H18CqpvDELug","colab_type":"code","outputId":"8e1df8fd-aedd-4acd-9f06-e88996380a5e","executionInfo":{"status":"ok","timestamp":1581545630257,"user_tz":480,"elapsed":2237285,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["cosine_similarity(get_matrix_row(matrix4, 'laboratory'), get_matrix_row(matrix4, 'monster'))  #was 0.0 - now 0.05321257140117508"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.05321257140117508"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"0tGmEt8IFQwj","colab_type":"text"},"source":["Check distances from monster in matrix4."]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"34384f0c-649e-4b22-897c-37f9b0713d46","id":"MO03TEc5FLcr","executionInfo":{"status":"ok","timestamp":1581546005190,"user_tz":480,"elapsed":2612207,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["%time monster_distances4 = word_distances(matrix4, 'monster') #on colab Wall time: 4min 51s"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 6min 12s, sys: 1.95 s, total: 6min 14s\n","Wall time: 6min 14s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PMbxsV3aIeQz","colab_type":"text"},"source":["Old:\n","<pre>\n","monster_distances[:10]\n","[('uncomplainingly', 0.23145502494313785),\n"," ('decipherer', 0.2182178902359924),\n"," ('hernani', 0.2182178902359924),\n"," ('mimes', 0.2182178902359924),\n"," ('skulking', 0.2182178902359924),\n"," ('ever', 0.19551857514700038),\n"," ('thought', 0.190143522496192),\n"," ('sentience', 0.17251638983558856),\n"," ('never', 0.1697162329953409),\n"," ('indistinctly', 0.1690308509457033)]\n","\n","</pre>\n","\n","New:\n","<pre>\n","monster_distances4[:10]\n","\n","[('us', 0.3268544199618383),\n"," ('yet', 0.3235339332908998),\n"," ('would', 0.32106693219271015),\n"," ('one', 0.3189100302265062),\n"," ('little', 0.3020545565519684),\n"," ('see', 0.3015976395691136),\n"," ('even', 0.3010299409924667),\n"," ('ever', 0.2988210673905941),\n"," ('could', 0.2983649085654773),\n"," ('must', 0.29647320153988244)]\n"," </pre>\n","\n"," Interesting. I think the old one (window size 1) is a little better than new one with window size 4."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3P2D_koWFLcu","outputId":"e1436f39-942f-4767-9d4e-6223c967bad4","executionInfo":{"status":"ok","timestamp":1581546005190,"user_tz":480,"elapsed":2612205,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["\n","monster_distances4[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('us', 0.3268544199618383),\n"," ('yet', 0.3235339332908998),\n"," ('would', 0.32106693219271015),\n"," ('one', 0.3189100302265062),\n"," ('little', 0.3020545565519684),\n"," ('see', 0.3015976395691136),\n"," ('even', 0.3010299409924667),\n"," ('ever', 0.2988210673905941),\n"," ('could', 0.2983649085654773),\n"," ('must', 0.29647320153988244)]"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"markdown","metadata":{"id":"yhPUuV7FCwv8","colab_type":"text"},"source":["<h2>\n","Closing notes\n","</h2>\n","\n","  Step back and see what is going on here. With `word_distances`, we are taking a target word and looking at its row vector. What is the row vector? It is the count of other words in  proximity of that word in all the sentences. So it represents \"the company the word keeps\". We now ask what other words keep similar company. If 2 words appear a lot together, that will make them similar. But they can also be similar if they never appear together. Instead, they appear with the same company often. For instance, take \"*Once in a blue moon.*\" and \"*A blue dog democrat.*\" Even if *moon* and *dog* may never appear together, they will be related through the *blue* column. So moon and dog will have some similarity. Kind of interesting.\n","  <p>\n","  \n","If we have time in the quarter, I'd like to follow up on the next step we can take once we have the comax. The general idea is that the comax is a very sparse matrix, consisting of mostly 0 entries. And as you have seen, it takes time to search it. There are linear-algebra  techniques for reducing a sparse matrix into a more dense matrix and hence, making them more computationally tractable to work with. One in particular is Singular-Value Decomposition (or SVD): https://en.wikipedia.org/wiki/Singular-value_decomposition. This is used with the Glove algorithm to take a comat, exactly like the one you built, and reduce it: https://nlp.stanford.edu/projects/glove/. You end up with a matrix of the same number of rows (one for each word) but roughly 300 columns (instead of 25K).  It's like magic!\n","<p>\n","This type of reduction is called \"word embedding\". It is like the 300 columns somehow capture the essence of the word in terms of its use in the context of a sentence. You can do some cool things with it. For instance, you can take the reduced vector for \"king', subtract the reduced vector for 'male' and get the resulting vector for 'queen'. It is too wild.\n","\n","I hope we can get to it toward the end of the quarter.\n","</div>"]}]}