{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"w20_module1_content.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eknokBfHibTF","colab_type":"text"},"source":["<h1>\n","<center>\n","Module 1: First look at text-based classification\n","</center>\n","</h1>\n","\n","\n","<p>The first real problem I'd like to look at in the course is classifying tweets as carrying fake-news (or not). But before getting to that in later modules, we need to pick up skills in what is called data wrangling and feature engineering. We will do that in this module. I am going to use a standard tutorial-type data set for machine learning: the passenger record of the Titanic steamship. The Titanic sunk on its maiden voyage. We have the record of the passengers. We will do a practice problem of predicting who survived and who perished based solely on their name. Will this be effective? Seems kind of like reading Tarot cards. But let's keep an open mind. Maybe it will work.\n","<p>\n","Many text-based machine-learning problems contain their data in spreadsheet form. Python has a powerful library for dealing with spreadsheets called pandas. In this module we will use a handful of features from the *`pandas`* library. I'll go through some basic clean-up steps using pandas. Common wisdom is that the clean-up process can take up to 70% of your entire effort. Life is messy. Text data comes to us in unstructured forms. We have to deal with it.\n"]},{"cell_type":"markdown","metadata":{"id":"HJvF35YqibTG","colab_type":"text"},"source":["<hr>\n","<h1>\n","Read in spreadsheet\n","</h1>\n","\n","\n","For the first part of the course, we will be working on a problem called classification. The data we will be using to make classifications will be in spreadsheet form (I'll also call this *table* form).\n","\n","We could read in the data to our own custom Python data-structure. Instead we will use the pandas library to store our data and modify it.\n","\n","I am going to use something called comma-separated values or csv as my raw file format. I like csv because you can use it to pass data around easily from things like Excel and google Sheets. And pandas knows how to read raw csv format and produce its own version called a Dataframe. Our week 2 goal is to read a table of tweets, in csv form, and classify them as fake-news or not.\n","\n","Caveat: I said we are interested in classification (e.g., fake-news or not) but I'll use the term `prediction` for the titanic. You can classification and prediction as interchangeable for now. I could say I am trying to `predict` who will survive or I could say I am trying to `classify` passengers into survivors and non-survivors. We will use the same methods for each.\n","\n","I have the titanic data stored on google sheets. I used sheets to give me a url to the csv version of the file. Once I have that url, I can hand it to pandas and suck it in. Pretty dang cool. You all have access to Google Sheets so you can do the same. If you have data in spreadsheet form, upload it to Sheets and then get the url. Now anyone can access your spreadsheet.\n","\n","BTW: it is convention to alias pandas as `pd`. It is also convention to use `df` as an abstract name for a Dataframe - you will see this in docs and StackOverflow. I am using `titanic_table` in place of `df` to give it more meaning.\n","\n"]},{"cell_type":"code","metadata":{"id":"Lk79RMEeibTH","colab_type":"code","outputId":"a5464851-360f-468c-e52f-ea0162f13c7b","executionInfo":{"status":"ok","timestamp":1579057023847,"user_tz":480,"elapsed":702,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["import pandas as pd\n","\n","url = 'https://docs.google.com/spreadsheets/d/1z1ycUZjJpmMWB4gXbhwRQ9B_qa42CwzAQkf82mLibxI/pub?output=csv'\n","titanic_table = pd.read_csv(url)\n","len(titanic_table)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["891"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"i6VphwUJibTi","colab_type":"code","colab":{}},"source":["#I am setting the option to see all the columns of our table as we build it, i.e., it has no max.\n","pd.set_option('display.max_columns', None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"btaJfg4xibTL","colab_type":"code","outputId":"43973985-3909-4d37-aca8-1434286bb104","executionInfo":{"status":"ok","timestamp":1579057031772,"user_tz":480,"elapsed":364,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["titanic_table.head()  #shows first 5 rows"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"9HGTGUsUrbTG","colab_type":"text"},"source":["<h2>Google Colab</h2>\n","\n","I will run all my notebooks through google colab. So I assume you downloaded this notebook from canvas and then uploaded it to your colab account."]},{"cell_type":"markdown","metadata":{"id":"2kztlve8ibTm","colab_type":"text"},"source":["<hr>\n","<h1>\n","Explore\n","</h1>\n","\n","We now have the 891 passengers in 891 rows of a table. We can use pandas methods to look a little more deeply at the data.\n","\n","* Use `head()` to get general layout. We did that above.</li>\n","* Find which columns have `NaN` (empties) and how many.</li>\n","* Use `describe` method to see if any odd looking columns, e.g., more than 2 unique values for a binary column.</li>\n"]},{"cell_type":"code","metadata":{"id":"_UuohntR-sCa","colab_type":"code","outputId":"a43736d9-f3fd-4e9a-f8e7-10342394cfad","executionInfo":{"status":"ok","timestamp":1579057035259,"user_tz":480,"elapsed":393,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["titanic_table.describe(include='all')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>714.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891</td>\n","      <td>891.000000</td>\n","      <td>204</td>\n","      <td>889</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>891</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>681</td>\n","      <td>NaN</td>\n","      <td>147</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Sheerlinck, Mr. Jan Baptist</td>\n","      <td>male</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>347082</td>\n","      <td>NaN</td>\n","      <td>G6</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>577</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>4</td>\n","      <td>644</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>446.000000</td>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>29.699118</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>NaN</td>\n","      <td>32.204208</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.353842</td>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>14.526497</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>NaN</td>\n","      <td>49.693429</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>NaN</td>\n","      <td>0.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>223.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>20.125000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>NaN</td>\n","      <td>7.910400</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>446.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>28.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>NaN</td>\n","      <td>14.454200</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>668.500000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>38.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>NaN</td>\n","      <td>31.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>891.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>NaN</td>\n","      <td>512.329200</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        PassengerId    Survived      Pclass                         Name  \\\n","count    891.000000  891.000000  891.000000                          891   \n","unique          NaN         NaN         NaN                          891   \n","top             NaN         NaN         NaN  Sheerlinck, Mr. Jan Baptist   \n","freq            NaN         NaN         NaN                            1   \n","mean     446.000000    0.383838    2.308642                          NaN   \n","std      257.353842    0.486592    0.836071                          NaN   \n","min        1.000000    0.000000    1.000000                          NaN   \n","25%      223.500000    0.000000    2.000000                          NaN   \n","50%      446.000000    0.000000    3.000000                          NaN   \n","75%      668.500000    1.000000    3.000000                          NaN   \n","max      891.000000    1.000000    3.000000                          NaN   \n","\n","         Sex         Age       SibSp       Parch  Ticket        Fare Cabin  \\\n","count    891  714.000000  891.000000  891.000000     891  891.000000   204   \n","unique     2         NaN         NaN         NaN     681         NaN   147   \n","top     male         NaN         NaN         NaN  347082         NaN    G6   \n","freq     577         NaN         NaN         NaN       7         NaN     4   \n","mean     NaN   29.699118    0.523008    0.381594     NaN   32.204208   NaN   \n","std      NaN   14.526497    1.102743    0.806057     NaN   49.693429   NaN   \n","min      NaN    0.420000    0.000000    0.000000     NaN    0.000000   NaN   \n","25%      NaN   20.125000    0.000000    0.000000     NaN    7.910400   NaN   \n","50%      NaN   28.000000    0.000000    0.000000     NaN   14.454200   NaN   \n","75%      NaN   38.000000    1.000000    0.000000     NaN   31.000000   NaN   \n","max      NaN   80.000000    8.000000    6.000000     NaN  512.329200   NaN   \n","\n","       Embarked  \n","count       889  \n","unique        3  \n","top           S  \n","freq        644  \n","mean        NaN  \n","std         NaN  \n","min         NaN  \n","25%         NaN  \n","50%         NaN  \n","75%         NaN  \n","max         NaN  "]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"nmVGus0NibTn","colab_type":"text"},"source":["<div class=just_text>\n","\n","There are a mixture of column types. Some have discrete values (e.g., `Pclass`, `Sex`, `Embarked`), some have continuous values (e.g., `Age`, `Fare`), and some are in between (e.g., `SibSp`, `Parch`). The `Name` column has text values. The `Ticket` and `Cabin` columns are a bit of a hodge podge and will take further wrangling to make them useful.\n","\n","Note that a `NaN` has several meanings. In the table above, it means \"does not apply\". For instance there is no std for the Name column so shows a NaN. More typically, a NaN will appear as a value in a table to stand for \"empty - no known value\". One more thing to note about it. It is not a string but a special value of pandas. So an attempt to do NaN == \"NaN\" will be false. You will have to use special pandas functions for dealing with a NaN.\n","\n","Let's next see how many empties there are in each column.\n","<div>"]},{"cell_type":"code","metadata":{"id":"QTY113SPibTo","colab_type":"code","outputId":"468f855e-e85c-4f1e-9433-5af14ced7e3e","executionInfo":{"status":"ok","timestamp":1579057041195,"user_tz":480,"elapsed":394,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":260}},"source":["titanic_table.isna().sum()  #note use of isna to find the NaNs."],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"5KGxIn2DibTt","colab_type":"text"},"source":["\n","* The `Age` column is a bit worrisome. It looks like a column that can be useful in prediction but has 177 empty values.\n","\n","* The `Cabin` column has a lot of empties. I am dubious that the column as a whole will be useful. However, it might make sense to use an empty/non-empty question. For instance, maybe passengers with non-empty cabins were more likely to survive.\n","\n","* The `Embarked` column has only 2 empties and that seems like something we can fill in.\n"]},{"cell_type":"markdown","metadata":{"id":"F78529BbibTz","colab_type":"text"},"source":["<hr>\n","<h1>Filter out unneeded columns</h1>\n","<p>\n","<div class=h1_cell>\n","<p>\n","\n","I am really only interested in the `Name` column and the `Survived` column. Since we are trying to predict Survived values, it is known as the target column or label column or just plain y. The other columns are called features or xi. I am saying that we will only be interested in Name so it is the sole feature (for now).\n","<p>\n"," My goal is to create a new table with just those 2 columns. There are 2 ways to go: (1) drop all the other columns, (2) copy over only the needed columns. I'll show you both ways. First, I'll first use the columns attribute to obtain all the columns. I turn this into a list to make it print more cleanly. I am doing this in prepraration of dropping most of them. I am being lazy - I just want to copy and paste the output into the drop method.\n","<p>\n","Note in the drop method I am using `axis=1` to say I am dropping columns and not rows (`axis=0`). \n","\n","</div>"]},{"cell_type":"code","metadata":{"id":"no5R8ol5ibT3","colab_type":"code","outputId":"401e44ae-5275-4a3a-b0ee-fb3d95f32231","executionInfo":{"status":"ok","timestamp":1579057043842,"user_tz":480,"elapsed":342,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["list(titanic_table.columns)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['PassengerId',\n"," 'Survived',\n"," 'Pclass',\n"," 'Name',\n"," 'Sex',\n"," 'Age',\n"," 'SibSp',\n"," 'Parch',\n"," 'Ticket',\n"," 'Fare',\n"," 'Cabin',\n"," 'Embarked']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"P6J2pkGcibT8","colab_type":"code","colab":{}},"source":["name_table_1 = titanic_table.drop(['PassengerId',\n","                                    'Pclass', \n","                                    'Sex',\n","                                     'Age',\n","                                     'SibSp',\n","                                     'Parch',\n","                                     'Ticket',\n","                                     'Fare',\n","                                     'Cabin',\n","                                     'Embarked'], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2EDLfNJBD110","colab_type":"code","outputId":"dbf8b616-c53e-4b7d-b995-18614f46fbab","executionInfo":{"status":"ok","timestamp":1579057047344,"user_tz":480,"elapsed":372,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["name_table_1.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>Allen, Mr. William Henry</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Survived                                               Name\n","0         0                            Braund, Mr. Owen Harris\n","1         1  Cumings, Mrs. John Bradley (Florence Briggs Th...\n","2         1                             Heikkinen, Miss. Laina\n","3         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)\n","4         0                           Allen, Mr. William Henry"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"9LvT-HIuibUB","colab_type":"text"},"source":["\n","\n","Most pandas operations make shallow copies of a table. This is true above: the drop method gives me a new table. Normally I would just reassign new table to `titanic_table`. This avoids keeping a lot of variables around like `titanic_table_1`, `titanic_table_2`, etc. I find trying to manage such a name space clumsy. It is true my way does not allow you to roll back to a prior version of the table. But you can \"roll forward\" by just restarting the kernel and executing all of the cells from the top of the notebook to get to a specific state.\n","\n","All that said, I am using a new var name above to demonstrate something. That comes next. Instead of dropping a bunch of columns, let's just add the 2 we want. Nice.\n"]},{"cell_type":"code","metadata":{"id":"cGYBxMiXDOlQ","colab_type":"code","colab":{}},"source":["name_table_2 = titanic_table[['Name', 'Survived']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1AKg5VBaDhGw","colab_type":"code","outputId":"6b3adffb-22e4-4ec5-aae5-d3905667bb4b","executionInfo":{"status":"ok","timestamp":1579057050236,"user_tz":480,"elapsed":357,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["name_table_2.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Name  Survived\n","0                            Braund, Mr. Owen Harris         0\n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...         1\n","2                             Heikkinen, Miss. Laina         1\n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)         1\n","4                           Allen, Mr. William Henry         0"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"2SR4qEyCibUJ","colab_type":"text"},"source":["<hr>\n","<h2>That's what I'm talkin about</h2>\n","<p>\n","<div class=h1_cell>\n","<p>\n","We trimmed down to the two columns we need. But as a warm up for word-vectorization in later modules, I am going to add a new column that is based on the Name column.\n","</div>"]},{"cell_type":"code","metadata":{"id":"WZjT-cylFMSf","colab_type":"code","colab":{}},"source":["#I'm going to reuse titanic_table var name to avoid proliferating names. If need to get full table back, redo steps at top of notebook.\n","\n","titanic_table = name_table_2  #or name_table_1 - they are equiv"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sQSI-NzZibUK","colab_type":"text"},"source":["<h2>Numerology</h2>\n","\n","I have a theory that the length of your full name gives a clue to your future. I'm going to add a new column, `Length`, so I can test this out a little later. You can see below that pandas makes this pretty easy to do.\n","\n","What is going on on the right hand side is that pandas `apply` is generating every row in turn and then passing that row to my lambda expression. The value returned by that lambda expression goes into the new column `Length`. If you like list comprehensions better, you can use this:\n","<pre>\n","titanic_table['Length'] = [len(row['Name']) for index,row in titanic_table.iterrows()]\n","</pre>\n","\n","The iterrows method gives you the same functionality but also includes the row index (which we are not using).\n"]},{"cell_type":"code","metadata":{"id":"lEfLKA38ibUL","colab_type":"code","outputId":"45baf111-9e5f-4fe4-b3a1-8d5abb270e51","executionInfo":{"status":"ok","timestamp":1579057072761,"user_tz":480,"elapsed":369,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["titanic_table['Length'] = titanic_table.apply(lambda row: len(row['Name']), axis=1)\n","titanic_table.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Survived</th>\n","      <th>Length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>0</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>1</td>\n","      <td>51</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>1</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>1</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>0</td>\n","      <td>24</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Name  Survived  Length\n","0                            Braund, Mr. Owen Harris         0      23\n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...         1      51\n","2                             Heikkinen, Miss. Laina         1      22\n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)         1      44\n","4                           Allen, Mr. William Henry         0      24"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"v2OmcR46ibUR","colab_type":"text"},"source":["<div class=just_text>\n","If you squint, you can almost believe that those who perished had shorter names.\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"GIsMJ-atibUT","colab_type":"text"},"source":["<hr>\n","<h2>Write the table out</h2>\n","\n","Let's save the work we have done with the table. Because I am using google colab, I have to autheticate myself before I can store the file. Note that I created a folder, `class_tables`, on My Drive on google drive. You can make up your own folder name if you wish.\n","<p>\n","  The first time you run this, you will be given a key to fill in and a website to visit. The website gives you the key. Copy it and type it in and hit enter.\n","</div>"]},{"cell_type":"code","metadata":{"id":"4JQTRYH4GmrF","colab_type":"code","outputId":"ee35e2cd-2842-4f0b-8157-c0eabb9d765b","executionInfo":{"status":"ok","timestamp":1579057291134,"user_tz":480,"elapsed":364,"user":{"displayName":"Future Deus","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDA38nWUBTrQ7no755EmiqFEck1JlL77eTTYOhS=s64","userId":"11509427916790811607"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NCqcnEPcibUU","colab_type":"code","colab":{}},"source":["with open('/content/gdrive/My Drive/class_tables/name_table.csv', 'w') as f:\n","  titanic_table.to_csv(f, encoding='utf-8', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"SBkDsujLibUY","colab_type":"text"},"source":["<hr>\n","<h1>\n","Use K-NN for classification\n","</h1>\n","<div class=h1_cell>\n","<p>\n","I said I was interested in predicting the Survived value for any passenger. This is a machine learning problem.  There are many machine-learning methods I might employ. But I am not ready to get into a comparison or survey at this point. I am just going to choose K Nearest Neighbor (K-NN) because it will get us going the fastest. It has its issues, but it is straightforward to build. And guess what, I am going to ask you to build it. It will look nice on your resume: \"I built K-NN from scratch.\"\n","<p>\n","I'll meet you over on the assignment notebook. I'll ask you to add more columns (features) to our table and then we can get K-NN built and then see if Numerology is legit. [spoiler alert] You might be surprised.\n","</div>"]}]}